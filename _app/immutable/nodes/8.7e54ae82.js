import{S as ko,i as fo,s as ho,k as p,l,m as u,h as a,n as v,b as o,F as t,H as va,V as mo,W as bo,q as k,a as m,r as f,c as b,E as co,G as _o,u as vo,y as bn,J as yo,z as dn,A as _n,g as vn,d as yn,B as wn,K as Os}from"../chunks/index.e3449a61.js";import"../chunks/paths.d33c6805.js";const wo=""+new URL("../assets/torch_loss.df06d0fc.png",import.meta.url).href,Eo=""+new URL("../assets/jax_loss.49ad9ea1.png",import.meta.url).href,go=""+new URL("../assets/torch_emb.8d851cc5.png",import.meta.url).href,Io=""+new URL("../assets/jax_emb.ae929fac.png",import.meta.url).href;function io(h,s,r){const i=h.slice();return i[4]=s[r],i}function uo(h){let s,r,i=h[4]+"",c,d,w,_;function E(){return h[3](h[4])}return{c(){s=p("li"),r=p("div"),c=k(i),d=m(),this.h()},l(I){s=l(I,"LI",{class:!0});var g=u(s);r=l(g,"DIV",{class:!0});var T=u(r);c=f(T,i),T.forEach(a),d=b(g),g.forEach(a),this.h()},h(){v(r,"class","svelte-s2w0x0"),co(r,"active",h[4]===h[1]),v(s,"class","svelte-s2w0x0")},m(I,g){o(I,s,g),t(s,r),t(r,c),t(s,d),w||(_=_o(s,"click",E),w=!0)},p(I,g){h=I,g&1&&i!==(i=h[4]+"")&&vo(c,i),g&3&&co(r,"active",h[4]===h[1])},d(I){I&&a(s),w=!1,_()}}}function To(h){let s,r,i=h[0],c=[];for(let d=0;d<i.length;d+=1)c[d]=uo(io(h,i,d));return{c(){s=p("div"),r=p("ul");for(let d=0;d<c.length;d+=1)c[d].c();this.h()},l(d){s=l(d,"DIV",{class:!0});var w=u(s);r=l(w,"UL",{class:!0});var _=u(r);for(let E=0;E<c.length;E+=1)c[E].l(_);_.forEach(a),w.forEach(a),this.h()},h(){v(r,"class","svelte-s2w0x0"),v(s,"class","tabs")},m(d,w){o(d,s,w),t(s,r);for(let _=0;_<c.length;_+=1)c[_]&&c[_].m(r,null)},p(d,[w]){if(w&7){i=d[0];let _;for(_=0;_<i.length;_+=1){const E=io(d,i,_);c[_]?c[_].p(E,w):(c[_]=uo(E),c[_].c(),c[_].m(r,null))}for(;_<c.length;_+=1)c[_].d(1);c.length=i.length}},i:va,o:va,d(d){d&&a(s),mo(c,d)}}}function Po(h,s,r){const i=bo();let{tabItems:c}=s,{activeItem:d}=s;const w=_=>i("tabChange",_);return h.$$set=_=>{"tabItems"in _&&r(0,c=_.tabItems),"activeItem"in _&&r(1,d=_.activeItem)},[c,d,i,w]}class En extends ko{constructor(s){super(),fo(this,s,Po,To,ho,{tabItems:0,activeItem:1})}}function Ao(h){let s,r=`<code class="language-python">alphabet_size <span class="token operator">=</span> <span class="token number">27</span>
context_size <span class="token operator">=</span> <span class="token number">3</span>
neurons <span class="token operator">=</span> <span class="token number">100</span>
d <span class="token operator">=</span> <span class="token number">2</span>

key <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>PRNGKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
key<span class="token punctuation">,</span> <span class="token operator">*</span>subkeys <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>split<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
subkeys <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>subkeys<span class="token punctuation">)</span>

C <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>subkeys<span class="token punctuation">)</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>alphabet_size<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">)</span>
W1 <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>subkeys<span class="token punctuation">)</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>d <span class="token operator">*</span> context_size<span class="token punctuation">,</span> neurons<span class="token punctuation">)</span><span class="token punctuation">)</span>
b1 <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>subkeys<span class="token punctuation">)</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>neurons<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>
W2 <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>subkeys<span class="token punctuation">)</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>neurons<span class="token punctuation">,</span> alphabet_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
b2 <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>subkeys<span class="token punctuation">)</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>alphabet_size<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>

parameters <span class="token operator">=</span> <span class="token punctuation">[</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">]</span></code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function $o(h){let s,r=`<code class="language-python">alphabet_size <span class="token operator">=</span> <span class="token number">27</span>
context_size <span class="token operator">=</span> <span class="token number">3</span>
neurons <span class="token operator">=</span> <span class="token number">100</span>
d <span class="token operator">=</span> <span class="token number">2</span>

g <span class="token operator">=</span> torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">2147483647</span><span class="token punctuation">)</span>

C <span class="token operator">=</span>  torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>generator<span class="token operator">=</span>g<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>alphabet_size<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">)</span>
W1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>generator<span class="token operator">=</span>g<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>d <span class="token operator">*</span> context_size<span class="token punctuation">,</span> neurons<span class="token punctuation">)</span><span class="token punctuation">)</span>
b1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>generator<span class="token operator">=</span>g<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>neurons<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>
W2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>generator<span class="token operator">=</span>g<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>neurons<span class="token punctuation">,</span> alphabet_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
b2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>generator<span class="token operator">=</span>g<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>alphabet_size<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>

parameters <span class="token operator">=</span> <span class="token punctuation">[</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">]</span></code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function Xo(h){let s,r=`<code class="language-python"><span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    emb <span class="token operator">=</span> C<span class="token punctuation">[</span>X<span class="token punctuation">]</span>
    h <span class="token operator">=</span> jnp<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>emb<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span> @ W1 <span class="token operator">+</span> b1<span class="token punctuation">)</span>
    logits <span class="token operator">=</span> h @ W2 <span class="token operator">+</span> b2
    logits <span class="token operator">-=</span> logits<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    counts <span class="token operator">=</span> jnp<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
    probs <span class="token operator">=</span> counts <span class="token operator">/</span> counts<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> probs</code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function Jo(h){let s,r=`<code class="language-python"><span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    emb <span class="token operator">=</span> C<span class="token punctuation">[</span>X<span class="token punctuation">]</span>
    h <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>emb<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span> @ W1 <span class="token operator">+</span> b1<span class="token punctuation">)</span>
    logits <span class="token operator">=</span> h @ W2 <span class="token operator">+</span> b2
    logits <span class="token operator">-=</span> logits<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values
    counts <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
    probs <span class="token operator">=</span> counts <span class="token operator">/</span> counts<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> probs</code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function Lo(h){let s,r=`<code class="language-python"><span class="token keyword">def</span> <span class="token function">loss_fn</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    probs <span class="token operator">=</span> model<span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> X<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span>jnp<span class="token punctuation">.</span>log<span class="token punctuation">(</span>probs<span class="token punctuation">[</span>jnp<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss</code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function Wo(h){let s,r=`<code class="language-python"><span class="token keyword">def</span> <span class="token function">loss_fn</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    probs <span class="token operator">=</span> model<span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> X<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>probs<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss</code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function Co(h){let s,r=`<code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Xb<span class="token punctuation">,</span> Yb<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    grad_fn <span class="token operator">=</span> grad<span class="token punctuation">(</span>loss_fn<span class="token punctuation">,</span> argnums<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    gC<span class="token punctuation">,</span> gW1<span class="token punctuation">,</span> gb1<span class="token punctuation">,</span> gW2<span class="token punctuation">,</span> gb2 <span class="token operator">=</span> grad_fn<span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Xb<span class="token punctuation">,</span> Yb<span class="token punctuation">)</span>

    C <span class="token operator">-=</span> lr <span class="token operator">*</span> gC
    W1 <span class="token operator">-=</span> lr <span class="token operator">*</span> gW1
    b1 <span class="token operator">-=</span> lr <span class="token operator">*</span> gb1
    W2 <span class="token operator">-=</span> lr <span class="token operator">*</span> gW2
    b2 <span class="token operator">-=</span> lr <span class="token operator">*</span> gb2

    <span class="token keyword">return</span> C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2</code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function jo(h){let s,r=`<code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Xb<span class="token punctuation">,</span> Yb<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Xb<span class="token punctuation">,</span> Yb<span class="token punctuation">)</span>

    <span class="token keyword">for</span> p <span class="token keyword">in</span> parameters<span class="token punctuation">:</span>
        p<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>

    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> p <span class="token keyword">in</span> parameters<span class="token punctuation">:</span>
        p<span class="token punctuation">.</span>data <span class="token operator">-=</span> lr <span class="token operator">*</span> p<span class="token punctuation">.</span>grad</code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function Ho(h){let s,r=`<code class="language-python">key <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>PRNGKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    key<span class="token punctuation">,</span> subkey <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>split<span class="token punctuation">(</span>key<span class="token punctuation">)</span>
    ix <span class="token operator">=</span> jrandom<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>subkey<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> minval<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> maxval<span class="token operator">=</span>Xtr<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    Xb<span class="token punctuation">,</span> Yb <span class="token operator">=</span> Xtr<span class="token punctuation">[</span>ix<span class="token punctuation">]</span><span class="token punctuation">,</span> Ytr<span class="token punctuation">[</span>ix<span class="token punctuation">]</span>
    C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2 <span class="token operator">=</span> train<span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Xb<span class="token punctuation">,</span> Yb<span class="token punctuation">)</span></code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function Mo(h){let s,r=`<code class="language-python">g <span class="token operator">=</span> torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">2147483647</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    ix <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> Xtr<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">)</span>
    Xb<span class="token punctuation">,</span> Yb <span class="token operator">=</span> Xtr<span class="token punctuation">[</span>ix<span class="token punctuation">]</span><span class="token punctuation">,</span> Ytr<span class="token punctuation">[</span>ix<span class="token punctuation">]</span>
    train<span class="token punctuation">(</span>C<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Xb<span class="token punctuation">,</span> Yb<span class="token punctuation">)</span></code>`;return{c(){s=p("pre"),this.h()},l(i){s=l(i,"PRE",{class:!0});var c=u(s);c.forEach(a),this.h()},h(){v(s,"class","language-python")},m(i,c){o(i,s,c),s.innerHTML=r},d(i){i&&a(s)}}}function zo(h){let s,r,i;return{c(){s=p("p"),r=p("img"),this.h()},l(c){s=l(c,"P",{});var d=u(s);r=l(d,"IMG",{src:!0,alt:!0}),d.forEach(a),this.h()},h(){Os(r.src,i=Eo)||v(r,"src",i),v(r,"alt","jax-loss")},m(c,d){o(c,s,d),t(s,r)},p:va,d(c){c&&a(s)}}}function Ro(h){let s,r,i;return{c(){s=p("p"),r=p("img"),this.h()},l(c){s=l(c,"P",{});var d=u(s);r=l(d,"IMG",{src:!0,alt:!0}),d.forEach(a),this.h()},h(){Os(r.src,i=wo)||v(r,"src",i),v(r,"alt","torch-loss")},m(c,d){o(c,s,d),t(s,r)},p:va,d(c){c&&a(s)}}}function Do(h){let s,r,i;return{c(){s=p("p"),r=p("img"),this.h()},l(c){s=l(c,"P",{});var d=u(s);r=l(d,"IMG",{src:!0,alt:!0}),d.forEach(a),this.h()},h(){Os(r.src,i=Io)||v(r,"src",i),v(r,"alt","jax-emb")},m(c,d){o(c,s,d),t(s,r)},p:va,d(c){c&&a(s)}}}function No(h){let s,r,i;return{c(){s=p("p"),r=p("img"),this.h()},l(c){s=l(c,"P",{});var d=u(s);r=l(d,"IMG",{src:!0,alt:!0}),d.forEach(a),this.h()},h(){Os(r.src,i=go)||v(r,"src",i),v(r,"alt","torch-emb")},m(c,d){o(c,s,d),t(s,r)},p:va,d(c){c&&a(s)}}}function Yo(h){let s,r,i,c,d,w,_,E,I,g,T,Y,C,X,G,P,J,L;return{c(){s=p("ul"),r=p("li"),i=k("brone"),c=m(),d=p("li"),w=k("jieai"),_=m(),E=p("li"),I=k("krillo"),g=m(),T=p("li"),Y=k("jrayle"),C=m(),X=p("li"),G=k("karireio"),P=m(),J=p("li"),L=k("addelie")},l(W){s=l(W,"UL",{});var y=u(s);r=l(y,"LI",{});var U=u(r);i=f(U,"brone"),U.forEach(a),c=b(y),d=l(y,"LI",{});var B=u(d);w=f(B,"jieai"),B.forEach(a),_=b(y),E=l(y,"LI",{});var q=u(E);I=f(q,"krillo"),q.forEach(a),g=b(y),T=l(y,"LI",{});var O=u(T);Y=f(O,"jrayle"),O.forEach(a),C=b(y),X=l(y,"LI",{});var j=u(X);G=f(j,"karireio"),j.forEach(a),P=b(y),J=l(y,"LI",{});var F=u(J);L=f(F,"addelie"),F.forEach(a),y.forEach(a)},m(W,y){o(W,s,y),t(s,r),t(r,i),t(s,c),t(s,d),t(d,w),t(s,_),t(s,E),t(E,I),t(s,g),t(s,T),t(T,Y),t(s,C),t(s,X),t(X,G),t(s,P),t(s,J),t(J,L)},d(W){W&&a(s)}}}function Go(h){let s,r,i,c,d,w,_,E,I,g,T,Y,C,X,G,P,J,L;return{c(){s=p("ul"),r=p("li"),i=k("junide"),c=m(),d=p("li"),w=k("janasad"),_=m(),E=p("li"),I=k("presay"),g=m(),T=p("li"),Y=k("adin"),C=m(),X=p("li"),G=k("koi"),P=m(),J=p("li"),L=k("ritolia")},l(W){s=l(W,"UL",{});var y=u(s);r=l(y,"LI",{});var U=u(r);i=f(U,"junide"),U.forEach(a),c=b(y),d=l(y,"LI",{});var B=u(d);w=f(B,"janasad"),B.forEach(a),_=b(y),E=l(y,"LI",{});var q=u(E);I=f(q,"presay"),q.forEach(a),g=b(y),T=l(y,"LI",{});var O=u(T);Y=f(O,"adin"),O.forEach(a),C=b(y),X=l(y,"LI",{});var j=u(X);G=f(j,"koi"),j.forEach(a),P=b(y),J=l(y,"LI",{});var F=u(J);L=f(F,"ritolia"),F.forEach(a),y.forEach(a)},m(W,y){o(W,s,y),t(s,r),t(r,i),t(s,c),t(s,d),t(d,w),t(s,_),t(s,E),t(E,I),t(s,g),t(s,T),t(T,Y),t(s,C),t(s,X),t(X,G),t(s,P),t(s,J),t(J,L)},d(W){W&&a(s)}}}function Bo(h){let s,r,i,c,d,w,_,E,I,g,T,Y,C,X,G,P,J,L,W,y,U,B,q,O,j,F,gn,Ks,qs,Oa,Wn,Fs,Ka,on,Ss,In,Vs,Zs,qa,Cn,Qs,Fa,jn,xs,Sa,Hn,nt,Va,Mn,at,Za,S,Qa,zn,pn,st,Tn,tt,et,xa,Rn,ot,ns,V,as,Dn,Nn,pt,ss,Yn,lt,ts,Z,es,Gn,K,ct,ya,it,ut,wa,rt,kt,os,Bn,ft,ps,Q,ls,Un,ln,ht,Ea,mt,bt,cs,cn,dt,ga,_t,vt,is,un,yt,Pn,wt,Et,us,On,gt,rs,x,ks,Kn,qn,It,fs,Fn,Tt,hs,rn,Pt,An,At,$t,ms,Sn,Xt,bs,Vn,Jt,ds,nn,_s,Zn,Qn,Lt,vs,an,ys,xn,na,Wt,ws,sn,Es,aa,sa,Ct,gs,ta,jt,Is,kn,Ia,$n,Ta,Ht,Mt,Pa,zt,Rt,Aa,Xn,$a,Dt,Nt,Xa,Yt,Ts,ea,Gt,Ps,fn,Bt,Ja,Ut,Ot,As,hn,La,tn,Wa,Kt,qt,Ca,Ft,St,ja,Vt,Zt,Ha,en,Ma,Qt,xt,za,ne,ae,Ra,se,$s,oa,te,Xs,pa,ee,Js,mn,oe,Jn,pe,le,Ls;S=new En({props:{tabItems:h[1],activeItem:h[0]}}),S.$on("tabChange",h[2]);function ce(n,e){if(n[0]==="Torch")return $o;if(n[0]==="JAX")return Ao}let la=ce(h),H=la&&la(h);V=new En({props:{tabItems:h[1],activeItem:h[0]}}),V.$on("tabChange",h[2]);function ie(n,e){if(n[0]==="Torch")return Jo;if(n[0]==="JAX")return Xo}let ca=ie(h),M=ca&&ca(h);Z=new En({props:{tabItems:h[1],activeItem:h[0]}}),Z.$on("tabChange",h[2]);function ue(n,e){if(n[0]==="Torch")return Wo;if(n[0]==="JAX")return Lo}let ia=ue(h),z=ia&&ia(h);Q=new En({props:{tabItems:h[1],activeItem:h[0]}}),Q.$on("tabChange",h[2]);function re(n,e){if(n[0]==="Torch")return jo;if(n[0]==="JAX")return Co}let ua=re(h),R=ua&&ua(h);x=new En({props:{tabItems:h[1],activeItem:h[0]}}),x.$on("tabChange",h[2]);function ke(n,e){if(n[0]==="Torch")return Mo;if(n[0]==="JAX")return Ho}let ra=ke(h),D=ra&&ra(h);nn=new En({props:{tabItems:h[1],activeItem:h[0]}}),nn.$on("tabChange",h[2]);function fe(n,e){if(n[0]==="Torch")return Ro;if(n[0]==="JAX")return zo}let ka=fe(h),A=ka&&ka(h);an=new En({props:{tabItems:h[1],activeItem:h[0]}}),an.$on("tabChange",h[2]);function he(n,e){if(n[0]==="Torch")return No;if(n[0]==="JAX")return Do}let fa=he(h),$=fa&&fa(h);sn=new En({props:{tabItems:h[1],activeItem:h[0]}}),sn.$on("tabChange",h[2]);function me(n,e){if(n[0]==="Torch")return Go;if(n[0]==="JAX")return Yo}let ha=me(h),N=ha&&ha(h);return{c(){s=m(),r=p("h1"),i=k(ro),c=m(),d=p("p"),w=p("a"),_=k("JAX"),E=k(` is a cool machine learning framework from Google.
Language models (LMs) are the family of models that include ChatGPT and GPT-4, which have taken the machine learning world by storm.`),I=m(),g=p("p"),T=k("What better way to learn about both than to implement a simple LM in JAX?"),Y=m(),C=p("h2"),X=k("Resources"),G=m(),P=p("p"),J=k("I’ll heavily rely on Andrej Karpathy’s amazing course "),L=p("a"),W=k("Neural Networks: Zero to Hero"),y=k(` for this implementation.
The course starts from the very basics of neural networks and slowly builds up to implementing a GPT model.`),U=m(),B=p("p"),q=k(`If you are interested in learning about all of these things in detail, I highly recommend checking the course out.
This blog post is only concerned about porting the implementation to JAX, and won’t go into the theoretical background of what is being implemented.`),O=m(),j=p("p"),F=k("As for JAX, I’ve found the "),gn=p("a"),Ks=k("official documentation"),qs=k(" adequate so far."),Oa=m(),Wn=p("h2"),Fs=k("Model"),Ka=m(),on=p("p"),Ss=k("The model I’m interested in building is the Multi Layer Perceptron (MLP) model from "),In=p("a"),Vs=k("Building makemore Part 2: MLP"),Zs=k(`.
I think this is a good starting point due to the simplicity of the model built in this chapter.`),qa=m(),Cn=p("p"),Qs=k("Following the steps in this video, I will be building a character-level LM that looks at the previous three characters to predict which character will come next."),Fa=m(),jn=p("h2"),xs=k("Implementation"),Sa=m(),Hn=p("p"),nt=k("While displaying the relevant code blocks, I’ll also provide the PyTorch counterparts in a separate tab for easier comparison."),Va=m(),Mn=p("p"),at=k("Let’s start by initializing the model parameters:"),Za=m(),bn(S.$$.fragment),Qa=m(),H&&H.c(),zn=m(),pn=p("p"),st=k(`You can notice they are very similar.
Other than method and parameter names, the only difference is how JAX handles random number generation.
You can read more about that in the corresponding section of `),Tn=p("a"),tt=k("🔪 JAX - The Sharp Bits 🔪"),et=k("."),xa=m(),Rn=p("p"),ot=k("Now let’s write the forward pass:"),ns=m(),bn(V.$$.fragment),as=m(),M&&M.c(),Dn=m(),Nn=p("p"),pt=k("Again very similar."),ss=m(),Yn=p("p"),lt=k("Now we need a loss function:"),ts=m(),bn(Z.$$.fragment),es=m(),z&&z.c(),Gn=m(),K=p("p"),ct=k("Here literally the only change is replacing "),ya=p("code"),it=k("torch"),ut=k(" with "),wa=p("code"),rt=k("jnp"),kt=k("."),os=m(),Bn=p("p"),ft=k("And now the training function, which is the first major difference between PyTorch and JAX:"),ps=m(),bn(Q.$$.fragment),ls=m(),R&&R.c(),Un=m(),ln=p("p"),ht=k("In PyTorch, we get a tensor from the loss function, which we can call "),Ea=p("code"),mt=k("backward"),bt=k(` on to backpropagate the gradients to our parameters.
Then, we can loop through all our parameters and update them in-place.
We also need to remember to clear up the gradients for each parameter after every iteration, otherwise they would accumulate.`),cs=m(),cn=p("p"),dt=k("In JAX, we use "),ga=p("code"),_t=k("grad"),vt=k(` on the loss function to obtain a new function that evaluates the gradients of that function with respect to the parameters we choose.
We then use that function to find the gradients at the current point in our parameter space, and use those gradients to update them.
Also notable: we need to return new arrays to replace the old ones, instead of updating them in-place as JAX follows a more functional paradigm than PyTorch.`),is=m(),un=p("p"),yt=k("Even though I passed each parameter and received their gradients explicitly in this implementation, JAX also has ways to pass all parameters and receive all gradients together using "),Pn=p("a"),wt=k("pytrees"),Et=k("."),us=m(),On=p("p"),gt=k("Finally, the training loop:"),rs=m(),bn(x.$$.fragment),ks=m(),D&&D.c(),Kn=m(),qn=p("p"),It=k("Again we see only minimal differences due to how the two libraries handle random number generation differently."),fs=m(),Fn=p("h2"),Tt=k("Data"),hs=m(),rn=p("p"),Pt=k("I’ll use the same "),An=p("a"),At=k("dataset of 32K English names"),$t=k(" as Andrej and split it into train / dev / test sets in the same way."),ms=m(),Sn=p("h2"),Xt=k("Training & Evaluation"),bs=m(),Vn=p("p"),Jt=k("Here are the training and dev losses during training:"),ds=m(),bn(nn.$$.fragment),_s=m(),A&&A.c(),Zn=m(),Qn=p("p"),Lt=k("These are the learned character embeddings:"),vs=m(),bn(an.$$.fragment),ys=m(),$&&$.c(),xn=m(),na=p("p"),Wt=k("These are a sample of names generated by the LM:"),ws=m(),bn(sn.$$.fragment),Es=m(),N&&N.c(),aa=m(),sa=p("h2"),Ct=k("Performance"),gs=m(),ta=p("p"),jt=k("If I run 10000 steps of training on my CPU based on the code presented above, I get the following times:"),Is=m(),kn=p("table"),Ia=p("thead"),$n=p("tr"),Ta=p("th"),Ht=k("PyTorch"),Mt=m(),Pa=p("th"),zt=k("JAX"),Rt=m(),Aa=p("tbody"),Xn=p("tr"),$a=p("td"),Dt=k("5.6s"),Nt=m(),Xa=p("td"),Yt=k("158s"),Ts=m(),ea=p("p"),Gt=k(`But JAX has one more core functionality I didn’t mention, Just In Time (JIT) compilation.
When a function is decorated with the JIT decorator, all the operations in that function get compiled into a more efficient version that can then be run on any input of the same shape and type.`),Ps=m(),fn=p("p"),Bt=k("After we JIT the "),Ja=p("code"),Ut=k("train"),Ot=k(" function, we get:"),As=m(),hn=p("table"),La=p("thead"),tn=p("tr"),Wa=p("th"),Kt=k("PyTorch"),qt=m(),Ca=p("th"),Ft=k("JAX"),St=m(),ja=p("th"),Vt=k("JAX (after JIT)"),Zt=m(),Ha=p("tbody"),en=p("tr"),Ma=p("td"),Qt=k("5.6s"),xt=m(),za=p("td"),ne=k("158s"),ae=m(),Ra=p("td"),se=k("5.9s"),$s=m(),oa=p("p"),te=k("Nobody would normally train language models on MacBook CPUs, but this at least gives an idea on the importance of knowing how to use JIT when using JAX."),Xs=m(),pa=p("h2"),ee=k("Conclusion"),Js=m(),mn=p("p"),oe=k(`I believe this was a good introduction to JAX and to implementing language models.
A good next step would be to implement the more sophisticated LMs from later in the series, and using that as an opportunity to learn `),Jn=p("a"),pe=k("Haiku"),le=k("!"),this.h()},l(n){yo("svelte-1lu3tjn",document.head).forEach(a),s=b(n),r=l(n,"H1",{});var Da=u(r);i=f(Da,ro),Da.forEach(a),c=b(n),d=l(n,"P",{});var ma=u(d);w=l(ma,"A",{href:!0,rel:!0});var Na=u(w);_=f(Na,"JAX"),Na.forEach(a),E=f(ma,` is a cool machine learning framework from Google.
Language models (LMs) are the family of models that include ChatGPT and GPT-4, which have taken the machine learning world by storm.`),ma.forEach(a),I=b(n),g=l(n,"P",{});var Ya=u(g);T=f(Ya,"What better way to learn about both than to implement a simple LM in JAX?"),Ya.forEach(a),Y=b(n),C=l(n,"H2",{});var Ga=u(C);X=f(Ga,"Resources"),Ga.forEach(a),G=b(n),P=l(n,"P",{});var Ln=u(P);J=f(Ln,"I’ll heavily rely on Andrej Karpathy’s amazing course "),L=l(Ln,"A",{href:!0,rel:!0});var Ba=u(L);W=f(Ba,"Neural Networks: Zero to Hero"),Ba.forEach(a),y=f(Ln,` for this implementation.
The course starts from the very basics of neural networks and slowly builds up to implementing a GPT model.`),Ln.forEach(a),U=b(n),B=l(n,"P",{});var Ua=u(B);q=f(Ua,`If you are interested in learning about all of these things in detail, I highly recommend checking the course out.
This blog post is only concerned about porting the implementation to JAX, and won’t go into the theoretical background of what is being implemented.`),Ua.forEach(a),O=b(n),j=l(n,"P",{});var Ws=u(j);F=f(Ws,"As for JAX, I’ve found the "),gn=l(Ws,"A",{href:!0,rel:!0});var be=u(gn);Ks=f(be,"official documentation"),be.forEach(a),qs=f(Ws," adequate so far."),Ws.forEach(a),Oa=b(n),Wn=l(n,"H2",{});var de=u(Wn);Fs=f(de,"Model"),de.forEach(a),Ka=b(n),on=l(n,"P",{});var Cs=u(on);Ss=f(Cs,"The model I’m interested in building is the Multi Layer Perceptron (MLP) model from "),In=l(Cs,"A",{href:!0,rel:!0});var _e=u(In);Vs=f(_e,"Building makemore Part 2: MLP"),_e.forEach(a),Zs=f(Cs,`.
I think this is a good starting point due to the simplicity of the model built in this chapter.`),Cs.forEach(a),qa=b(n),Cn=l(n,"P",{});var ve=u(Cn);Qs=f(ve,"Following the steps in this video, I will be building a character-level LM that looks at the previous three characters to predict which character will come next."),ve.forEach(a),Fa=b(n),jn=l(n,"H2",{});var ye=u(jn);xs=f(ye,"Implementation"),ye.forEach(a),Sa=b(n),Hn=l(n,"P",{});var we=u(Hn);nt=f(we,"While displaying the relevant code blocks, I’ll also provide the PyTorch counterparts in a separate tab for easier comparison."),we.forEach(a),Va=b(n),Mn=l(n,"P",{});var Ee=u(Mn);at=f(Ee,"Let’s start by initializing the model parameters:"),Ee.forEach(a),Za=b(n),dn(S.$$.fragment,n),Qa=b(n),H&&H.l(n),zn=b(n),pn=l(n,"P",{});var js=u(pn);st=f(js,`You can notice they are very similar.
Other than method and parameter names, the only difference is how JAX handles random number generation.
You can read more about that in the corresponding section of `),Tn=l(js,"A",{href:!0,rel:!0});var ge=u(Tn);tt=f(ge,"🔪 JAX - The Sharp Bits 🔪"),ge.forEach(a),et=f(js,"."),js.forEach(a),xa=b(n),Rn=l(n,"P",{});var Ie=u(Rn);ot=f(Ie,"Now let’s write the forward pass:"),Ie.forEach(a),ns=b(n),dn(V.$$.fragment,n),as=b(n),M&&M.l(n),Dn=b(n),Nn=l(n,"P",{});var Te=u(Nn);pt=f(Te,"Again very similar."),Te.forEach(a),ss=b(n),Yn=l(n,"P",{});var Pe=u(Yn);lt=f(Pe,"Now we need a loss function:"),Pe.forEach(a),ts=b(n),dn(Z.$$.fragment,n),es=b(n),z&&z.l(n),Gn=b(n),K=l(n,"P",{});var ba=u(K);ct=f(ba,"Here literally the only change is replacing "),ya=l(ba,"CODE",{});var Ae=u(ya);it=f(Ae,"torch"),Ae.forEach(a),ut=f(ba," with "),wa=l(ba,"CODE",{});var $e=u(wa);rt=f($e,"jnp"),$e.forEach(a),kt=f(ba,"."),ba.forEach(a),os=b(n),Bn=l(n,"P",{});var Xe=u(Bn);ft=f(Xe,"And now the training function, which is the first major difference between PyTorch and JAX:"),Xe.forEach(a),ps=b(n),dn(Q.$$.fragment,n),ls=b(n),R&&R.l(n),Un=b(n),ln=l(n,"P",{});var Hs=u(ln);ht=f(Hs,"In PyTorch, we get a tensor from the loss function, which we can call "),Ea=l(Hs,"CODE",{});var Je=u(Ea);mt=f(Je,"backward"),Je.forEach(a),bt=f(Hs,` on to backpropagate the gradients to our parameters.
Then, we can loop through all our parameters and update them in-place.
We also need to remember to clear up the gradients for each parameter after every iteration, otherwise they would accumulate.`),Hs.forEach(a),cs=b(n),cn=l(n,"P",{});var Ms=u(cn);dt=f(Ms,"In JAX, we use "),ga=l(Ms,"CODE",{});var Le=u(ga);_t=f(Le,"grad"),Le.forEach(a),vt=f(Ms,` on the loss function to obtain a new function that evaluates the gradients of that function with respect to the parameters we choose.
We then use that function to find the gradients at the current point in our parameter space, and use those gradients to update them.
Also notable: we need to return new arrays to replace the old ones, instead of updating them in-place as JAX follows a more functional paradigm than PyTorch.`),Ms.forEach(a),is=b(n),un=l(n,"P",{});var zs=u(un);yt=f(zs,"Even though I passed each parameter and received their gradients explicitly in this implementation, JAX also has ways to pass all parameters and receive all gradients together using "),Pn=l(zs,"A",{href:!0,rel:!0});var We=u(Pn);wt=f(We,"pytrees"),We.forEach(a),Et=f(zs,"."),zs.forEach(a),us=b(n),On=l(n,"P",{});var Ce=u(On);gt=f(Ce,"Finally, the training loop:"),Ce.forEach(a),rs=b(n),dn(x.$$.fragment,n),ks=b(n),D&&D.l(n),Kn=b(n),qn=l(n,"P",{});var je=u(qn);It=f(je,"Again we see only minimal differences due to how the two libraries handle random number generation differently."),je.forEach(a),fs=b(n),Fn=l(n,"H2",{});var He=u(Fn);Tt=f(He,"Data"),He.forEach(a),hs=b(n),rn=l(n,"P",{});var Rs=u(rn);Pt=f(Rs,"I’ll use the same "),An=l(Rs,"A",{href:!0,rel:!0});var Me=u(An);At=f(Me,"dataset of 32K English names"),Me.forEach(a),$t=f(Rs," as Andrej and split it into train / dev / test sets in the same way."),Rs.forEach(a),ms=b(n),Sn=l(n,"H2",{});var ze=u(Sn);Xt=f(ze,"Training & Evaluation"),ze.forEach(a),bs=b(n),Vn=l(n,"P",{});var Re=u(Vn);Jt=f(Re,"Here are the training and dev losses during training:"),Re.forEach(a),ds=b(n),dn(nn.$$.fragment,n),_s=b(n),A&&A.l(n),Zn=b(n),Qn=l(n,"P",{});var De=u(Qn);Lt=f(De,"These are the learned character embeddings:"),De.forEach(a),vs=b(n),dn(an.$$.fragment,n),ys=b(n),$&&$.l(n),xn=b(n),na=l(n,"P",{});var Ne=u(na);Wt=f(Ne,"These are a sample of names generated by the LM:"),Ne.forEach(a),ws=b(n),dn(sn.$$.fragment,n),Es=b(n),N&&N.l(n),aa=b(n),sa=l(n,"H2",{});var Ye=u(sa);Ct=f(Ye,"Performance"),Ye.forEach(a),gs=b(n),ta=l(n,"P",{});var Ge=u(ta);jt=f(Ge,"If I run 10000 steps of training on my CPU based on the code presented above, I get the following times:"),Ge.forEach(a),Is=b(n),kn=l(n,"TABLE",{});var Ds=u(kn);Ia=l(Ds,"THEAD",{});var Be=u(Ia);$n=l(Be,"TR",{});var Ns=u($n);Ta=l(Ns,"TH",{});var Ue=u(Ta);Ht=f(Ue,"PyTorch"),Ue.forEach(a),Mt=b(Ns),Pa=l(Ns,"TH",{});var Oe=u(Pa);zt=f(Oe,"JAX"),Oe.forEach(a),Ns.forEach(a),Be.forEach(a),Rt=b(Ds),Aa=l(Ds,"TBODY",{});var Ke=u(Aa);Xn=l(Ke,"TR",{});var Ys=u(Xn);$a=l(Ys,"TD",{});var qe=u($a);Dt=f(qe,"5.6s"),qe.forEach(a),Nt=b(Ys),Xa=l(Ys,"TD",{});var Fe=u(Xa);Yt=f(Fe,"158s"),Fe.forEach(a),Ys.forEach(a),Ke.forEach(a),Ds.forEach(a),Ts=b(n),ea=l(n,"P",{});var Se=u(ea);Gt=f(Se,`But JAX has one more core functionality I didn’t mention, Just In Time (JIT) compilation.
When a function is decorated with the JIT decorator, all the operations in that function get compiled into a more efficient version that can then be run on any input of the same shape and type.`),Se.forEach(a),Ps=b(n),fn=l(n,"P",{});var Gs=u(fn);Bt=f(Gs,"After we JIT the "),Ja=l(Gs,"CODE",{});var Ve=u(Ja);Ut=f(Ve,"train"),Ve.forEach(a),Ot=f(Gs," function, we get:"),Gs.forEach(a),As=b(n),hn=l(n,"TABLE",{});var Bs=u(hn);La=l(Bs,"THEAD",{});var Ze=u(La);tn=l(Ze,"TR",{});var da=u(tn);Wa=l(da,"TH",{});var Qe=u(Wa);Kt=f(Qe,"PyTorch"),Qe.forEach(a),qt=b(da),Ca=l(da,"TH",{});var xe=u(Ca);Ft=f(xe,"JAX"),xe.forEach(a),St=b(da),ja=l(da,"TH",{});var no=u(ja);Vt=f(no,"JAX (after JIT)"),no.forEach(a),da.forEach(a),Ze.forEach(a),Zt=b(Bs),Ha=l(Bs,"TBODY",{});var ao=u(Ha);en=l(ao,"TR",{});var _a=u(en);Ma=l(_a,"TD",{});var so=u(Ma);Qt=f(so,"5.6s"),so.forEach(a),xt=b(_a),za=l(_a,"TD",{});var to=u(za);ne=f(to,"158s"),to.forEach(a),ae=b(_a),Ra=l(_a,"TD",{});var eo=u(Ra);se=f(eo,"5.9s"),eo.forEach(a),_a.forEach(a),ao.forEach(a),Bs.forEach(a),$s=b(n),oa=l(n,"P",{});var oo=u(oa);te=f(oo,"Nobody would normally train language models on MacBook CPUs, but this at least gives an idea on the importance of knowing how to use JIT when using JAX."),oo.forEach(a),Xs=b(n),pa=l(n,"H2",{});var po=u(pa);ee=f(po,"Conclusion"),po.forEach(a),Js=b(n),mn=l(n,"P",{});var Us=u(mn);oe=f(Us,`I believe this was a good introduction to JAX and to implementing language models.
A good next step would be to implement the more sophisticated LMs from later in the series, and using that as an opportunity to learn `),Jn=l(Us,"A",{href:!0,rel:!0});var lo=u(Jn);pe=f(lo,"Haiku"),lo.forEach(a),le=f(Us,"!"),Us.forEach(a),this.h()},h(){document.title="Doga Tekin on Learning JAX",v(w,"href","https://github.com/google/jax"),v(w,"rel","nofollow"),v(L,"href","https://karpathy.ai/zero-to-hero.html"),v(L,"rel","nofollow"),v(gn,"href","https://jax.readthedocs.io/en/latest/index.html"),v(gn,"rel","nofollow"),v(In,"href","https://www.youtube.com/watch?v=TCH_1BHY58I"),v(In,"rel","nofollow"),v(Tn,"href","https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#random-numbers"),v(Tn,"rel","nofollow"),v(Pn,"href","https://jax.readthedocs.io/en/latest/jax-101/05.1-pytrees.html"),v(Pn,"rel","nofollow"),v(An,"href","https://github.com/karpathy/makemore/blob/master/names.txt"),v(An,"rel","nofollow"),v(Jn,"href","https://github.com/deepmind/dm-haiku"),v(Jn,"rel","nofollow")},m(n,e){o(n,s,e),o(n,r,e),t(r,i),o(n,c,e),o(n,d,e),t(d,w),t(w,_),t(d,E),o(n,I,e),o(n,g,e),t(g,T),o(n,Y,e),o(n,C,e),t(C,X),o(n,G,e),o(n,P,e),t(P,J),t(P,L),t(L,W),t(P,y),o(n,U,e),o(n,B,e),t(B,q),o(n,O,e),o(n,j,e),t(j,F),t(j,gn),t(gn,Ks),t(j,qs),o(n,Oa,e),o(n,Wn,e),t(Wn,Fs),o(n,Ka,e),o(n,on,e),t(on,Ss),t(on,In),t(In,Vs),t(on,Zs),o(n,qa,e),o(n,Cn,e),t(Cn,Qs),o(n,Fa,e),o(n,jn,e),t(jn,xs),o(n,Sa,e),o(n,Hn,e),t(Hn,nt),o(n,Va,e),o(n,Mn,e),t(Mn,at),o(n,Za,e),_n(S,n,e),o(n,Qa,e),H&&H.m(n,e),o(n,zn,e),o(n,pn,e),t(pn,st),t(pn,Tn),t(Tn,tt),t(pn,et),o(n,xa,e),o(n,Rn,e),t(Rn,ot),o(n,ns,e),_n(V,n,e),o(n,as,e),M&&M.m(n,e),o(n,Dn,e),o(n,Nn,e),t(Nn,pt),o(n,ss,e),o(n,Yn,e),t(Yn,lt),o(n,ts,e),_n(Z,n,e),o(n,es,e),z&&z.m(n,e),o(n,Gn,e),o(n,K,e),t(K,ct),t(K,ya),t(ya,it),t(K,ut),t(K,wa),t(wa,rt),t(K,kt),o(n,os,e),o(n,Bn,e),t(Bn,ft),o(n,ps,e),_n(Q,n,e),o(n,ls,e),R&&R.m(n,e),o(n,Un,e),o(n,ln,e),t(ln,ht),t(ln,Ea),t(Ea,mt),t(ln,bt),o(n,cs,e),o(n,cn,e),t(cn,dt),t(cn,ga),t(ga,_t),t(cn,vt),o(n,is,e),o(n,un,e),t(un,yt),t(un,Pn),t(Pn,wt),t(un,Et),o(n,us,e),o(n,On,e),t(On,gt),o(n,rs,e),_n(x,n,e),o(n,ks,e),D&&D.m(n,e),o(n,Kn,e),o(n,qn,e),t(qn,It),o(n,fs,e),o(n,Fn,e),t(Fn,Tt),o(n,hs,e),o(n,rn,e),t(rn,Pt),t(rn,An),t(An,At),t(rn,$t),o(n,ms,e),o(n,Sn,e),t(Sn,Xt),o(n,bs,e),o(n,Vn,e),t(Vn,Jt),o(n,ds,e),_n(nn,n,e),o(n,_s,e),A&&A.m(n,e),o(n,Zn,e),o(n,Qn,e),t(Qn,Lt),o(n,vs,e),_n(an,n,e),o(n,ys,e),$&&$.m(n,e),o(n,xn,e),o(n,na,e),t(na,Wt),o(n,ws,e),_n(sn,n,e),o(n,Es,e),N&&N.m(n,e),o(n,aa,e),o(n,sa,e),t(sa,Ct),o(n,gs,e),o(n,ta,e),t(ta,jt),o(n,Is,e),o(n,kn,e),t(kn,Ia),t(Ia,$n),t($n,Ta),t(Ta,Ht),t($n,Mt),t($n,Pa),t(Pa,zt),t(kn,Rt),t(kn,Aa),t(Aa,Xn),t(Xn,$a),t($a,Dt),t(Xn,Nt),t(Xn,Xa),t(Xa,Yt),o(n,Ts,e),o(n,ea,e),t(ea,Gt),o(n,Ps,e),o(n,fn,e),t(fn,Bt),t(fn,Ja),t(Ja,Ut),t(fn,Ot),o(n,As,e),o(n,hn,e),t(hn,La),t(La,tn),t(tn,Wa),t(Wa,Kt),t(tn,qt),t(tn,Ca),t(Ca,Ft),t(tn,St),t(tn,ja),t(ja,Vt),t(hn,Zt),t(hn,Ha),t(Ha,en),t(en,Ma),t(Ma,Qt),t(en,xt),t(en,za),t(za,ne),t(en,ae),t(en,Ra),t(Ra,se),o(n,$s,e),o(n,oa,e),t(oa,te),o(n,Xs,e),o(n,pa,e),t(pa,ee),o(n,Js,e),o(n,mn,e),t(mn,oe),t(mn,Jn),t(Jn,pe),t(mn,le),Ls=!0},p(n,[e]){const Da={};e&1&&(Da.activeItem=n[0]),S.$set(Da),la!==(la=ce(n))&&(H&&H.d(1),H=la&&la(n),H&&(H.c(),H.m(zn.parentNode,zn)));const ma={};e&1&&(ma.activeItem=n[0]),V.$set(ma),ca!==(ca=ie(n))&&(M&&M.d(1),M=ca&&ca(n),M&&(M.c(),M.m(Dn.parentNode,Dn)));const Na={};e&1&&(Na.activeItem=n[0]),Z.$set(Na),ia!==(ia=ue(n))&&(z&&z.d(1),z=ia&&ia(n),z&&(z.c(),z.m(Gn.parentNode,Gn)));const Ya={};e&1&&(Ya.activeItem=n[0]),Q.$set(Ya),ua!==(ua=re(n))&&(R&&R.d(1),R=ua&&ua(n),R&&(R.c(),R.m(Un.parentNode,Un)));const Ga={};e&1&&(Ga.activeItem=n[0]),x.$set(Ga),ra!==(ra=ke(n))&&(D&&D.d(1),D=ra&&ra(n),D&&(D.c(),D.m(Kn.parentNode,Kn)));const Ln={};e&1&&(Ln.activeItem=n[0]),nn.$set(Ln),ka===(ka=fe(n))&&A?A.p(n,e):(A&&A.d(1),A=ka&&ka(n),A&&(A.c(),A.m(Zn.parentNode,Zn)));const Ba={};e&1&&(Ba.activeItem=n[0]),an.$set(Ba),fa===(fa=he(n))&&$?$.p(n,e):($&&$.d(1),$=fa&&fa(n),$&&($.c(),$.m(xn.parentNode,xn)));const Ua={};e&1&&(Ua.activeItem=n[0]),sn.$set(Ua),ha!==(ha=me(n))&&(N&&N.d(1),N=ha&&ha(n),N&&(N.c(),N.m(aa.parentNode,aa)))},i(n){Ls||(vn(S.$$.fragment,n),vn(V.$$.fragment,n),vn(Z.$$.fragment,n),vn(Q.$$.fragment,n),vn(x.$$.fragment,n),vn(nn.$$.fragment,n),vn(an.$$.fragment,n),vn(sn.$$.fragment,n),Ls=!0)},o(n){yn(S.$$.fragment,n),yn(V.$$.fragment,n),yn(Z.$$.fragment,n),yn(Q.$$.fragment,n),yn(x.$$.fragment,n),yn(nn.$$.fragment,n),yn(an.$$.fragment,n),yn(sn.$$.fragment,n),Ls=!1},d(n){n&&a(s),n&&a(r),n&&a(c),n&&a(d),n&&a(I),n&&a(g),n&&a(Y),n&&a(C),n&&a(G),n&&a(P),n&&a(U),n&&a(B),n&&a(O),n&&a(j),n&&a(Oa),n&&a(Wn),n&&a(Ka),n&&a(on),n&&a(qa),n&&a(Cn),n&&a(Fa),n&&a(jn),n&&a(Sa),n&&a(Hn),n&&a(Va),n&&a(Mn),n&&a(Za),wn(S,n),n&&a(Qa),H&&H.d(n),n&&a(zn),n&&a(pn),n&&a(xa),n&&a(Rn),n&&a(ns),wn(V,n),n&&a(as),M&&M.d(n),n&&a(Dn),n&&a(Nn),n&&a(ss),n&&a(Yn),n&&a(ts),wn(Z,n),n&&a(es),z&&z.d(n),n&&a(Gn),n&&a(K),n&&a(os),n&&a(Bn),n&&a(ps),wn(Q,n),n&&a(ls),R&&R.d(n),n&&a(Un),n&&a(ln),n&&a(cs),n&&a(cn),n&&a(is),n&&a(un),n&&a(us),n&&a(On),n&&a(rs),wn(x,n),n&&a(ks),D&&D.d(n),n&&a(Kn),n&&a(qn),n&&a(fs),n&&a(Fn),n&&a(hs),n&&a(rn),n&&a(ms),n&&a(Sn),n&&a(bs),n&&a(Vn),n&&a(ds),wn(nn,n),n&&a(_s),A&&A.d(n),n&&a(Zn),n&&a(Qn),n&&a(vs),wn(an,n),n&&a(ys),$&&$.d(n),n&&a(xn),n&&a(na),n&&a(ws),wn(sn,n),n&&a(Es),N&&N.d(n),n&&a(aa),n&&a(sa),n&&a(gs),n&&a(ta),n&&a(Is),n&&a(kn),n&&a(Ts),n&&a(ea),n&&a(Ps),n&&a(fn),n&&a(As),n&&a(hn),n&&a($s),n&&a(oa),n&&a(Xs),n&&a(pa),n&&a(Js),n&&a(mn)}}}const Uo={title:"Learning JAX by Implementing a Simple Language Model",date:"2023-04-25"},{title:ro,date:Fo}=Uo;function Oo(h,s,r){let i=["Torch","JAX"],c="JAX";return[c,i,w=>{r(0,c=w.detail)}]}class So extends ko{constructor(s){super(),fo(this,s,Oo,Bo,ho,{})}}export{So as component};
